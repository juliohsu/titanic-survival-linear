{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/juliohsu/titanic-survival-linear-regression?scriptVersionId=198456864\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-27T03:42:59.344205Z","iopub.execute_input":"2024-09-27T03:42:59.34511Z","iopub.status.idle":"2024-09-27T03:42:59.353587Z","shell.execute_reply.started":"2024-09-27T03:42:59.345058Z","shell.execute_reply":"2024-09-27T03:42:59.352445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Analysis and Exploration","metadata":{}},{"cell_type":"code","source":"# if you want to display full dataset, change '20' to 'None'\npd.set_option('display.max_rows', 20)\n\n# overview the training set\nX_train = pd.read_csv('/kaggle/input/titanic/train.csv')\nX_test = pd.read_csv('/kaggle/input/titanic/test.csv')\n\nX_train","metadata":{"execution":{"iopub.status.busy":"2024-09-27T03:42:59.355568Z","iopub.execute_input":"2024-09-27T03:42:59.356604Z","iopub.status.idle":"2024-09-27T03:42:59.392006Z","shell.execute_reply.started":"2024-09-27T03:42:59.356555Z","shell.execute_reply":"2024-09-27T03:42:59.390804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Pre-Processing: Missing Value","metadata":{}},{"cell_type":"code","source":"# first check for the missings value\nX_train.info()","metadata":{"execution":{"iopub.status.busy":"2024-09-27T03:42:59.393721Z","iopub.execute_input":"2024-09-27T03:42:59.394105Z","iopub.status.idle":"2024-09-27T03:42:59.407417Z","shell.execute_reply.started":"2024-09-27T03:42:59.394063Z","shell.execute_reply":"2024-09-27T03:42:59.406218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# handle feature \"age\" missings value by zero\ndef missing_age(X):\n    age_col = pd.DataFrame(X, columns=['Age'])\n    X['Age'] = age_col.fillna(0)\n\nmissing_age(X_train)\nmissing_age(X_test)\n    \nX_train['Age'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-09-27T03:42:59.410068Z","iopub.execute_input":"2024-09-27T03:42:59.410497Z","iopub.status.idle":"2024-09-27T03:42:59.423105Z","shell.execute_reply.started":"2024-09-27T03:42:59.410454Z","shell.execute_reply":"2024-09-27T03:42:59.421888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# handle feature 'fare' missings value by social class mode\ndef missing_fare(X):\n    fare_class = {\n        1: X[X['Pclass'] == 1]['Fare'].mean(),\n        2: X[X['Pclass'] == 2]['Fare'].mean(),\n        3: X[X['Pclass'] == 3]['Fare'].mean()\n    }\n    for passenger_index in range(X.shape[0]):\n        passenger_fare = X.iloc[passenger_index]['Fare']\n        if pd.isna(passenger_fare):\n            passenger_class = X.iloc[passenger_index]['Pclass']\n            for class_type in fare_class:\n                if passenger_class == class_type:\n                    X.loc[passenger_index, 'Fare'] = fare_class[class_type]\n                    \nmissing_fare(X_test)\n\nX_test['Fare'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-09-27T03:42:59.424649Z","iopub.execute_input":"2024-09-27T03:42:59.42502Z","iopub.status.idle":"2024-09-27T03:42:59.479164Z","shell.execute_reply.started":"2024-09-27T03:42:59.424979Z","shell.execute_reply":"2024-09-27T03:42:59.477931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# handle feature 'cabin' missings value by social class mode and family name\ndef missing_cabin(X):\n    \n    fcabin_dict = {}\n    \n    for passenger_index in range(X.shape[0]):\n        family_name = X.iloc[passenger_index]['Name'].split(' ', 1)[0]\n        passenger_cabin = X.iloc[passenger_index]['Cabin']\n        if family_name not in fcabin_dict:\n            if pd.isna(passenger_cabin):\n                fcabin_dict[family_name] = ''\n            else:\n                fcabin_dict[family_name] = passenger_cabin\n            \n    cabin_class = {\n        1: X[X['Pclass'] == 1]['Cabin'].mode().iloc[0],\n        2: X[X['Pclass'] == 2]['Cabin'].mode().iloc[0],\n        3: X[X['Pclass'] == 3]['Cabin'].mode().iloc[0]\n    }\n    \n    for passenger_index in range(X.shape[0]):\n        passenger_cabin = X.iloc[passenger_index]['Cabin']\n        if pd.isna(passenger_cabin):\n            passenger_class = X.iloc[passenger_index]['Pclass']\n            passenger_fname = X.iloc[passenger_index]['Name'].split(' ', 1)[0]\n            for class_type in cabin_class:\n                if passenger_class == class_type:\n                    family_cabin = fcabin_dict[passenger_fname]\n                    if family_cabin == '':\n                        random_cabin = cabin_class[class_type] + str(np.random.randint(999))\n                        X.loc[passenger_index, 'Cabin'] = random_cabin\n                        fcabin_dict[passenger_fname] = random_cabin\n                    else:\n                        X.loc[passenger_index, 'Cabin'] = family_cabin\n\nmissing_cabin(X_train)\nmissing_cabin(X_test)\n\nX_train['Cabin'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-09-27T03:42:59.480594Z","iopub.execute_input":"2024-09-27T03:42:59.484071Z","iopub.status.idle":"2024-09-27T03:43:00.304629Z","shell.execute_reply.started":"2024-09-27T03:42:59.484024Z","shell.execute_reply":"2024-09-27T03:43:00.303392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# handle feature \"embarked\" missings value by embarked mode\ndef missing_embarked(X):\n    embarked_mode = X['Embarked'].mode().iloc[0]\n    X['Embarked'] = X['Embarked'].fillna(embarked_mode)\n\nmissing_embarked(X_train)\nmissing_embarked(X_test)\n    \nX_train['Embarked'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-09-27T03:43:00.305974Z","iopub.execute_input":"2024-09-27T03:43:00.306343Z","iopub.status.idle":"2024-09-27T03:43:00.318973Z","shell.execute_reply.started":"2024-09-27T03:43:00.306287Z","shell.execute_reply":"2024-09-27T03:43:00.317679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# last check for the missings value\nX_train.info()","metadata":{"execution":{"iopub.status.busy":"2024-09-27T03:43:00.320457Z","iopub.execute_input":"2024-09-27T03:43:00.320904Z","iopub.status.idle":"2024-09-27T03:43:00.33586Z","shell.execute_reply.started":"2024-09-27T03:43:00.320862Z","shell.execute_reply":"2024-09-27T03:43:00.334662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Pre-Processing: Feature Increment","metadata":{}},{"cell_type":"code","source":"# first check for the features\nX_train","metadata":{"execution":{"iopub.status.busy":"2024-09-27T03:43:00.33994Z","iopub.execute_input":"2024-09-27T03:43:00.340648Z","iopub.status.idle":"2024-09-27T03:43:00.363651Z","shell.execute_reply.started":"2024-09-27T03:43:00.340592Z","shell.execute_reply":"2024-09-27T03:43:00.362467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create new feature 'deck' by type of cabin classification, e.g. 'C321' to 'C'\ndef create_deck(X):\n    X['Deck'] = ''\n    for passenger_index in range(X.shape[0]):\n        passenger_cabin = X.iloc[passenger_index]['Cabin']\n        passenger_class = X.iloc[passenger_index]['Pclass']\n        X.loc[passenger_index, 'Deck'] = list(passenger_cabin)[0]\n\ncreate_deck(X_train)\ncreate_deck(X_test) # a lots of nan value of its passenger cabin list\n\nX_train","metadata":{"execution":{"iopub.status.busy":"2024-09-27T03:43:00.365004Z","iopub.execute_input":"2024-09-27T03:43:00.365394Z","iopub.status.idle":"2024-09-27T03:43:00.925077Z","shell.execute_reply.started":"2024-09-27T03:43:00.365342Z","shell.execute_reply":"2024-09-27T03:43:00.923867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# simplify the feature 'name' by type of honorific title name, e.g. below\nhonorific_title = {\n    'Mr': ['Mr.', 'Major.', 'Rev.', 'Dr.', 'Col.', 'Capt.', 'Countess.', 'Don.'],\n    'Mrs': ['Mrs.', 'Ms.','Lady.', 'Mlle.'],\n    'Master': ['Master.'],\n    'Miss': ['Miss.']\n}\n\ndef simplify_name(X):\n    X['TitleName'] = ''\n    for passenger_index in range(X.shape[0]):\n        passenger_title = X.iloc[passenger_index]['Name'].split(' ', 2)[1]\n        for title in honorific_title:\n            if passenger_title in honorific_title[title]:\n                X.loc[passenger_index, 'TitleName'] = title\n\n# because we are modifying dataset metadata, so we must update the test dataset too\nsimplify_name(X_train)\nsimplify_name(X_test)\n\n\nX_train['TitleName']","metadata":{"execution":{"iopub.status.busy":"2024-09-27T03:43:00.926368Z","iopub.execute_input":"2024-09-27T03:43:00.92676Z","iopub.status.idle":"2024-09-27T03:43:01.352995Z","shell.execute_reply.started":"2024-09-27T03:43:00.92672Z","shell.execute_reply":"2024-09-27T03:43:01.351864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# last check for the features\nX_train","metadata":{"execution":{"iopub.status.busy":"2024-09-27T03:43:01.354665Z","iopub.execute_input":"2024-09-27T03:43:01.355159Z","iopub.status.idle":"2024-09-27T03:43:01.379476Z","shell.execute_reply.started":"2024-09-27T03:43:01.355104Z","shell.execute_reply":"2024-09-27T03:43:01.3783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Pre-Processing: Feature Decrement","metadata":{}},{"cell_type":"code","source":"# remove unnecessary feature like 'id'\nX_ids = X_train.pop('PassengerId')\nX_test_ids = X_test.pop('PassengerId')\n\n# preparing target feature\ny_train = X_train.pop('Survived')\n\nlen(y_train)","metadata":{"execution":{"iopub.status.busy":"2024-09-27T03:43:01.381088Z","iopub.execute_input":"2024-09-27T03:43:01.381591Z","iopub.status.idle":"2024-09-27T03:43:01.392548Z","shell.execute_reply.started":"2024-09-27T03:43:01.381526Z","shell.execute_reply":"2024-09-27T03:43:01.391347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# last check for the features\nX_train","metadata":{"execution":{"iopub.status.busy":"2024-09-27T03:43:01.3939Z","iopub.execute_input":"2024-09-27T03:43:01.394348Z","iopub.status.idle":"2024-09-27T03:43:01.419165Z","shell.execute_reply.started":"2024-09-27T03:43:01.394275Z","shell.execute_reply":"2024-09-27T03:43:01.417783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Scaling","metadata":{}},{"cell_type":"code","source":"X_train.info()","metadata":{"execution":{"iopub.status.busy":"2024-09-27T03:43:01.420717Z","iopub.execute_input":"2024-09-27T03:43:01.421193Z","iopub.status.idle":"2024-09-27T03:43:01.43672Z","shell.execute_reply.started":"2024-09-27T03:43:01.421136Z","shell.execute_reply":"2024-09-27T03:43:01.435376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\n# categorical and numeric features pipeline\ncat_col = X_train.select_dtypes(include=['object']).columns.tolist()\nnum_col = X_train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n\nencoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\nscaler = StandardScaler()\n\ntransformer = ColumnTransformer(\n    transformers = [\n        ('cat', encoder, cat_col),\n        ('num', scaler, num_col)\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-27T03:43:01.438288Z","iopub.execute_input":"2024-09-27T03:43:01.439142Z","iopub.status.idle":"2024-09-27T03:43:01.449985Z","shell.execute_reply.started":"2024-09-27T03:43:01.439093Z","shell.execute_reply":"2024-09-27T03:43:01.448802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Splitting","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size=0.80, random_state=42)\n\nprint(len(X_train), len(y_train))","metadata":{"execution":{"iopub.status.busy":"2024-09-27T03:43:01.45139Z","iopub.execute_input":"2024-09-27T03:43:01.451778Z","iopub.status.idle":"2024-09-27T03:43:01.467771Z","shell.execute_reply.started":"2024-09-27T03:43:01.451737Z","shell.execute_reply":"2024-09-27T03:43:01.466075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\nlinear_model = Pipeline(\n    steps = [\n        ('transformer', transformer),\n        ('linear', LinearRegression())\n    ]\n)\n\nlinear_model.fit(X_train, y_train)\n\ny_pred = linear_model.predict(X_val)\n\nmse = mean_squared_error(y_val, y_pred)\n\nmse","metadata":{"execution":{"iopub.status.busy":"2024-09-27T03:43:01.469644Z","iopub.execute_input":"2024-09-27T03:43:01.471245Z","iopub.status.idle":"2024-09-27T03:43:02.649774Z","shell.execute_reply.started":"2024-09-27T03:43:01.471151Z","shell.execute_reply":"2024-09-27T03:43:02.648775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test CSV Submission","metadata":{}},{"cell_type":"code","source":"test_id = pd.read_csv('/kaggle/input/titanic/gender_submission.csv')['PassengerId']\n\ntest_pred = linear_model.predict(X_test)\n\npd.DataFrame({\n    'PassengerId': test_id,\n    'Survived': test_pred\n}).to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-27T03:43:02.651394Z","iopub.execute_input":"2024-09-27T03:43:02.653133Z","iopub.status.idle":"2024-09-27T03:43:02.754144Z","shell.execute_reply.started":"2024-09-27T03:43:02.653078Z","shell.execute_reply":"2024-09-27T03:43:02.752504Z"},"trusted":true},"execution_count":null,"outputs":[]}]}